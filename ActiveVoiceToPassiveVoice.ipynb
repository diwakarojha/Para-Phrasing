{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ActiveVoiceToPassiveVoice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4nvKgNku4BQyIUV07jR9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c22b897071c0410c9de7b74d5294d992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d218e7240e44a7a9bccf5e5c31d5a44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bfa7a4d869934dcf86c12faa2c475c19",
              "IPY_MODEL_e19932ccb7ac4c37904ff9acabb09980"
            ]
          }
        },
        "2d218e7240e44a7a9bccf5e5c31d5a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bfa7a4d869934dcf86c12faa2c475c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8ddf0339a954fde8392c6fd20d7fddc",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a57b76ad19ae44269d732015356b82e3"
          }
        },
        "e19932ccb7ac4c37904ff9acabb09980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33535be1b60a49cc81b0f310d4d68811",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b255525524ca4c1493c9b1d59e1a9d04"
          }
        },
        "b8ddf0339a954fde8392c6fd20d7fddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a57b76ad19ae44269d732015356b82e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33535be1b60a49cc81b0f310d4d68811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b255525524ca4c1493c9b1d59e1a9d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diwakarojha/Para-Phrasing/blob/main/ActiveVoiceToPassiveVoice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqgPRtzPs2sy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVOTPaCps-n8",
        "outputId": "76558666-018a-4d16-8d64-cc020d51757d"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/01/5df6324efdc3f79025ea7eaf19478936c401a16dae4fd3fbd29f7d426974/pytorch_lightning-1.2.6-py3-none-any.whl (829kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 19.1MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.4.1)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.7MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.8.1+cu101)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (54.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.28.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning) (3.8.1)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch_lightning) (3.4.1)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 56.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (20.3.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Building wheels for collected packages: future, PyYAML\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=5beb89933eeedb514fdf91061f40c59a31073a1f75c7618269fd716ea54d1f2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=85b561487486b6f1841923c473013744588a64c75d52e57d65382ce26477c208\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built future PyYAML\n",
            "Installing collected packages: future, torchmetrics, PyYAML, async-timeout, multidict, yarl, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-0.8.7 future-0.18.2 multidict-5.1.0 pytorch-lightning-1.2.6 torchmetrics-0.2.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jY3R1beuIjU",
        "outputId": "df1a6f67-df38-452a-bc8a-6b01567cce0c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\r\u001b[K     |▏                               | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 31.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 24.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 23.6MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 17.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 18.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 17.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 17.7MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 163kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174kB 17.7MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 204kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 225kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235kB 17.7MB/s eta 0:00:01\r\u001b[K     |████                            | 245kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 266kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 286kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 296kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 307kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 317kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 327kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 337kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 348kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 358kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 368kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 378kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 389kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 399kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 409kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 419kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 430kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 440kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 450kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 460kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 471kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 481kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 491kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 501kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 512kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 522kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 532kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 542kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 563kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 573kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 583kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 593kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 604kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 614kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 624kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 634kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 645kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 655kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 665kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 675kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 686kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 696kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 706kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 716kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 727kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 737kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 747kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 757kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 768kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 778kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 788kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 798kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 808kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 819kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 829kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 839kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 849kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 860kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 870kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 880kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 890kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 901kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 911kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 921kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 931kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 942kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 952kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 962kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 972kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 983kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 993kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.0MB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=dca55ef107bdc2cfede938d0d201175cb35196a36738d9cfd62d6c59598cfbd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDBpgec1LcM",
        "outputId": "3c3ba214-2087-4b4a-b690-db9a91a287a0"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 24.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 26.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 28.7MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 18.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 19.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 19.0MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 19.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 19.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlXYei_RuLQl",
        "outputId": "0a150d0b-cbc0-4cb9-c318-a18a55d60c47"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypa42VFauQOG"
      },
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y6foyS_uS1E"
      },
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(T5FineTuner, self).__init__()\n",
        "        self.hparams = hparams\n",
        "\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "\n",
        "    def is_logger(self):\n",
        "        return True #self.trainer.proc_rank <= 0\n",
        "\n",
        "    def forward(\n",
        "            self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "    ):\n",
        "        return self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            lm_labels=lm_labels,\n",
        "        )\n",
        "\n",
        "    def _step(self, batch):\n",
        "        lm_labels = batch[\"target_ids\"]\n",
        "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            lm_labels=lm_labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "\n",
        "        tensorboard_logs = {\"train_loss\": loss}\n",
        "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "        self.opt = optimizer\n",
        "        return [optimizer]\n",
        "\n",
        "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n",
        "        if self.trainer.use_tpu:\n",
        "            xm.optimizer_step(optimizer)\n",
        "        else:\n",
        "            optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "    def get_tqdm_dict(self):\n",
        "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "        return tqdm_dict\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
        "        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n",
        "                                num_workers=4)\n",
        "        t_total = (\n",
        "                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "                // self.hparams.gradient_accumulation_steps\n",
        "                * float(self.hparams.num_train_epochs)\n",
        "        )\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "        self.lr_scheduler = scheduler\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"dev\", args=self.hparams)\n",
        "        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "  def on_test_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Test results *****\")\n",
        "\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "\n",
        "      # Log and save results to file\n",
        "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "      with open(output_test_results_file, \"w\") as writer:\n",
        "        for key in sorted(metrics):\n",
        "          if key not in [\"log\", \"progress_bar\"]:\n",
        "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "WCptMg7AuVXc",
        "outputId": "831c83c3-9eff-4e97-a534-49d901b4f154"
      },
      "source": [
        "# Load Dataset\n",
        "data = pd.read_excel(\"/content/Active to Passive Dataset.xlsx\",)#.astype(str)\n",
        "data.tail(150)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Active</th>\n",
              "      <th>Passive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Harry ate six shrimp at dinner.</td>\n",
              "      <td>At dinner, six shrimp were eaten by Harry.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beautiful giraffes roam the savannah.</td>\n",
              "      <td>The savannah is roamed by beautiful giraffes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sue changed the flat tire.</td>\n",
              "      <td>The flat tire was changed by Sue.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We are going to watch a movie tonight.</td>\n",
              "      <td>A movie is going to be watched by us tonight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I ran the obstacle course in record time.</td>\n",
              "      <td>The obstacle course was run by me in record ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Drinking coffee is something that many profess...</td>\n",
              "      <td>Drinking coffee is recommended by many profess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>By drinking approximately 2.5 or 3 liters of w...</td>\n",
              "      <td>By drinking approximately 2.5 or 3 liters of w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>We’ve been calling her phone for a long time b...</td>\n",
              "      <td>Her phone is called by us for a long time but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>After talking to me, some things about my life...</td>\n",
              "      <td>After I was talked by you, some things have be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>The information we share about our daily life ...</td>\n",
              "      <td>Information shared about daily life on the Int...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Active                                            Passive\n",
              "0                     Harry ate six shrimp at dinner.         At dinner, six shrimp were eaten by Harry. \n",
              "1               Beautiful giraffes roam the savannah.      The savannah is roamed by beautiful giraffes. \n",
              "2                          Sue changed the flat tire.                  The flat tire was changed by Sue. \n",
              "3              We are going to watch a movie tonight.      A movie is going to be watched by us tonight. \n",
              "4           I ran the obstacle course in record time.   The obstacle course was run by me in record ti...\n",
              "..                                                 ...                                                ...\n",
              "111  Drinking coffee is something that many profess...  Drinking coffee is recommended by many profess...\n",
              "112  By drinking approximately 2.5 or 3 liters of w...  By drinking approximately 2.5 or 3 liters of w...\n",
              "113  We’ve been calling her phone for a long time b...  Her phone is called by us for a long time but ...\n",
              "114  After talking to me, some things about my life...  After I was talked by you, some things have be...\n",
              "115  The information we share about our daily life ...  Information shared about daily life on the Int...\n",
              "\n",
              "[116 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmJodBaWuqfn",
        "outputId": "97e06ea2-89df-41e0-eec0-ed9a71f654f4"
      },
      "source": [
        "data_train=data.iloc[:100,:]\n",
        "data_train.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Active   100 non-null    object\n",
            " 1   Passive  100 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEGwKpyPvPLN",
        "outputId": "a4820fca-04fa-4abb-eb24-4ab58883611a"
      },
      "source": [
        "data_dev=data.iloc[100:108,:]\n",
        "data_dev.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8 entries, 100 to 107\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Active   8 non-null      object\n",
            " 1   Passive  8 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 260.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3h2P3yIvuza",
        "outputId": "82603113-8787-4826-a0df-365c9d4814a0"
      },
      "source": [
        "data_test=data.iloc[108:,:]\n",
        "data_test.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8 entries, 108 to 115\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Active   8 non-null      object\n",
            " 1   Passive  8 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 260.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ29IajswG4h",
        "outputId": "118bc5d0-3e38-48cb-a366-039b226266f5"
      },
      "source": [
        "print('Training data: ', data_train.shape)\n",
        "print('Validation data: ', data_dev.shape)\n",
        "print('Test data: ', data_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data:  (100, 2)\n",
            "Validation data:  (8, 2)\n",
            "Test data:  (8, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMuUzdqezQWb"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5_I3hPg0BFo"
      },
      "source": [
        "#data_train_1 = data_train_1.drop(['id', 'label'], axis=1).reset_index(drop=True)\n",
        "#data_dev_1 = data_dev_1.drop(['id', 'label'], axis=1).reset_index(drop=True)\n",
        "#data_test_1 = data_test_1.drop(['id', 'label'], axis=1).reset_index(drop=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAJhWwXo0Dvs"
      },
      "source": [
        "#data_train_1.to_csv (\"data/train.tsv\", sep='\\t',index = False)\n",
        "#data_dev_1.to_csv (\"data/dev.tsv\", sep='\\t',index = False)\n",
        "#data_test_1.to_csv (\"data/test.tsv\", sep='\\t',index = False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0O0kXcAzeHM"
      },
      "source": [
        "data_train.to_csv(\"data/train.tsv\",sep='\\t',index = False)\n",
        "data_dev.to_csv(\"data/dev.tsv\",sep='\\t', index = False)\n",
        "data_test.to_csv(\"data/test.tsv\",sep='\\t', index = False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVx7rPi2w21n"
      },
      "source": [
        "## Set arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dBX2zXwH_9",
        "outputId": "2772b062-d00e-4285-b700-745336561ca5"
      },
      "source": [
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-small',\n",
        "    tokenizer_name_or_path='t5-small',\n",
        "    max_seq_length=256,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=1,\n",
        "    eval_batch_size=1,\n",
        "    num_train_epochs=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    n_gpu=1,\n",
        "    early_stop_callback=False,\n",
        "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
        "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
        "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "train_path = \"data/train.tsv\"\n",
        "val_path = \"data/dev.tsv\"\n",
        "\n",
        "train = pd.read_csv(train_path, sep=\"\\t\").astype(str)\n",
        "print(train.head())\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                       Active                                            Passive\n",
            "0            Harry ate six shrimp at dinner.         At dinner, six shrimp were eaten by Harry. \n",
            "1      Beautiful giraffes roam the savannah.      The savannah is roamed by beautiful giraffes. \n",
            "2                 Sue changed the flat tire.                  The flat tire was changed by Sue. \n",
            "3     We are going to watch a movie tonight.      A movie is going to be watched by us tonight. \n",
            "4  I ran the obstacle course in record time.   The obstacle course was run by me in record ti...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y5UHwYV6YqC",
        "outputId": "cf05e124-beb2-47f2-d9ca-5e2ae018a743"
      },
      "source": [
        "print(tokenizer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PreTrainedTokenizer(name_or_path='t5-small', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "QxJCJM1J1zHR",
        "outputId": "3be63e24-0409-4f81-dd9c-5636d1cbf2f8"
      },
      "source": [
        "# from transformers import AutoTokenizer\n",
        "# from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/t5-tiny-random\")\n",
        "\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/t5-tiny-random\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-1df6e9f77a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"patrickvonplaten/t5-tiny-random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__version__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmbart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_mbart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMBartTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmbart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_mbart50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMBart50Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmt5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMT5Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpegasus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_pegasus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_reformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReformerTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/mt5/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MT5Tokenizer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMT5Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MT5TokenizerFast\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMT5TokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MT5Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwfdiwLvw8Iw"
      },
      "source": [
        "## ParaphraseDataset()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFTVcou0wzW7"
      },
      "source": [
        "class ParaphraseDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data_dir, type_path, max_len=512):\n",
        "        self.path = os.path.join(data_dir, type_path + '.tsv')\n",
        "\n",
        "        self.source_column = \"Active\"\n",
        "        self.target_column = \"Passive\"\n",
        "        self.data = pd.read_csv(self.path, sep=\"\\t\").astype(str)\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "\n",
        "    def _build(self):\n",
        "        for idx in range(len(self.data)):\n",
        "            input_, target = self.data.loc[idx, self.source_column], self.data.loc[idx, self.target_column]\n",
        "\n",
        "            input_ = \"paraphrase: \"+ input_ + ' </s>'\n",
        "            target = target + \" </s>\"\n",
        "\n",
        "            # tokenize inputs\n",
        "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\", truncation='longest_first'\n",
        "            )\n",
        "            # tokenize targets\n",
        "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                [target], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\", truncation='longest_first'\n",
        "            )\n",
        "\n",
        "            self.inputs.append(tokenized_inputs)\n",
        "            self.targets.append(tokenized_targets)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYL6-CkPxECj"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849,
          "referenced_widgets": [
            "c22b897071c0410c9de7b74d5294d992",
            "2d218e7240e44a7a9bccf5e5c31d5a44",
            "bfa7a4d869934dcf86c12faa2c475c19",
            "e19932ccb7ac4c37904ff9acabb09980",
            "b8ddf0339a954fde8392c6fd20d7fddc",
            "a57b76ad19ae44269d732015356b82e3",
            "33535be1b60a49cc81b0f310d4d68811",
            "b255525524ca4c1493c9b1d59e1a9d04"
          ]
        },
        "id": "WHnFIuDLxDHa",
        "outputId": "e00d7810-9ca0-4ef7-cca9-d476e3005316"
      },
      "source": [
        "dataset = ParaphraseDataset(tokenizer, 'data', 'dev', 256)\n",
        "print(\"Val dataset: \",len(dataset))\n",
        "\n",
        "data = dataset[1]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))\n",
        "\n",
        "if not os.path.exists('t5_paraphrase'):\n",
        "    os.makedirs('t5_paraphrase')\n",
        "\n",
        "args_dict.update({'data_dir': 'data', 'output_dir': 't5_paraphrase', 'num_train_epochs':10,'max_seq_length':256})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)\n",
        "\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    dirpath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        " #   early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")\n",
        "\n",
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return ParaphraseDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)\n",
        "\n",
        "print (\"Initialize model\")\n",
        "model = T5FineTuner(args)\n",
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "print (\" Training model\")\n",
        "trainer.fit(model)\n",
        "\n",
        "print (\"training finished\")\n",
        "\n",
        "print (\"Saving model\")\n",
        "model.model.save_pretrained('t5_paraphrase')\n",
        "\n",
        "print (\"Model saved\")\n",
        "\n",
        "!cp \"/content/t5_paraphrase/\" -a \"/content/drive/My Drive/\"\n",
        "!cp \"/content/lightning_logs/\" -a \"/content/drive/My Drive/\"\n",
        "print (\"Copied the final folder to Google Drive\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:175: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val dataset:  8\n",
            "paraphrase: Our work was really successful, but we could not prevent a small error at the end of the work. It was very sad for everyone to experience this situation.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "The work done was really successful, but a small error could not be prevented at the end of the work. Everyone was very upset by this situation.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "{'data_dir': 'data', 'output_dir': 't5_paraphrase', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'max_seq_length': 256, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 1, 'eval_batch_size': 1, 'num_train_epochs': 10, 'gradient_accumulation_steps': 1, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n",
            "Initialize model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Training model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 60.5 M\n",
            "-----------------------------------------------------\n",
            "60.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "60.5 M    Total params\n",
            "242.026   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c22b897071c0410c9de7b74d5294d992",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-72f6a136ee14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" Training model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"training finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3778429040a2>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3778429040a2>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3778429040a2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, lm_labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'lm_labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfF9fviCxRCO"
      },
      "source": [
        "## Start Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb-TSaIBxWf4"
      },
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "#  if torch.cuda.is_available():\n",
        "#   torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "best_model_path = \"drive/My Drive/Inabia NLP Models/T5-large-fine-tuned-2 epoch (PAWS)/t5_paraphrase\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(best_model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device \",device)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB97XWx9xcOO"
      },
      "source": [
        "sentence_1 = \"Washing your hands Properly will keep you away from COVID-19.\"\n",
        "sentence_2 = \"Wikipedia was launched on January 15, 2001, and was created by Jimmy Wales and Larry Sanger.\"\n",
        "sentence_3 = \"NLP is one of the interesting fields for Data Scientists to focus on.\"\n",
        "sentence_4 = \"Do I really need to take a flu shot if I’m healthy with few or no underlying conditions?\"\n",
        "sentence_5 = \"Which course should I take to get started in data science?\"\n",
        "sentence_6 = \"There will be 3 Walmart Black Friday events held in November starting on November 4, November 11 and November 25!\"\n",
        "sentence_7 = \"The FCC says the $200 million civil penalty is the largest fixed-amount penalty in the commission's history.\"\n",
        "sentence_8 = \"Southwest Airlines travelers can now fly directly from San Diego to Honolulu on a new service that took off Wednesday out of the San Diego International Airport.\"\n",
        "sentence_9 = \"Gasoline production averaged 9.1 million bpd last week, slightly down on the previous week.\"\n",
        "sentence_10 = \"If you fall into the latter group, here’s how to replace Google’s new icons for Gmail, Calendar, and other apps with the older, arguably better versions on Android, iPhone, and Chrome.\"\n",
        "sentence_11 = \"Apple has been working on ARM-based Macs for some time, but only made them official at this year's WWDC.\"\n",
        "sentence_12 = \"Microsoft is investigating reports that some users are seeing error 0x80070426 when using their Microsoft account to sign into various apps.\"\n",
        "sentence_13 = \"On Saturday, Connery’s family announced that the Oscar-winning Scottish actor died peacefully in his sleep at home in the Bahamas.\"\n",
        "sentence_14 = \"Baby Shark Dance, from South Korean brand Pinkfong, officially surpassed the song by Luis Fonsi as the most viewed YouTube video of all time, having racked up 7.05 billion views to 7.04 billion.\"\n",
        "sentence_15 = \"The University of Washington has informed the NFL office that due to an increase in COVID-19 infection rate and indications of increased community spread in the local area, NFL personnel are no longer allowed to attend games at Husky Stadium.\"\n",
        "sentence_16 = \"The NBA's basketball-related income was down $1.5 billion last season, according to data provided to teams and obtained by ESPN.\"\n",
        "sentence_17 = \"Yesterday, the huge orbiting laboratory celebrated 20 years of continuous human occupation, a big milestone in humanity's push to extend its footprint into the final frontier.\"\n",
        "sentence_18 = \"A team of researchers led by Osaka University and National Taiwan University created a system of nanoscale silicon resonators that can act as logic gates for light pulses.\"\n",
        "sentence_19 = \"The research on 100 people shows that all had T-cell responses against a range of the coronavirus’s proteins, including the spike protein used as a marker in many vaccine studies, after half a year.\"\n",
        "sentence_20 = \"A group of researchers at MIT recently developed an artificial intelligence model that can detect asymptomatic COVID-19 cases by listening to subtle differences in coughs between healthy people and infected people.\"\n",
        "\n",
        "sentence = sentence_3\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "print (\"\\nOriginal sentence: \")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased sentences: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drDi9FPWxjC3"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDsiUtQIxmP6"
      },
      "source": [
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "best_model_path = \"drive/My Drive/Inabia NLP Models/T5-large-fine-tuned-2 epoch (PAWS)/t5_paraphrase\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(best_model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-large')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3qV80WBxpC0"
      },
      "source": [
        "def similarity(x):\n",
        "    input_ids = tokenizer.encode(str(x), return_tensors='pt')\n",
        "    outputs = model.generate(input_ids=input_ids)\n",
        "    similarityd = tokenizer.decode(outputs[0])\n",
        "    return similarityd"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}